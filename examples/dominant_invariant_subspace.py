# Autogenerated with SMOP 
from smop.core import *
# dominant_invariant_subspace.m

    
@function
def dominant_invariant_subspace(A=None,p=None,*args,**kwargs):
    varargin = dominant_invariant_subspace.varargin
    nargin = dominant_invariant_subspace.nargin

    # Returns an orthonormal basis of the dominant invariant p-subspace of A.
    
    # function X = dominant_invariant_subspace(A, p)
    
    # Input: A real, symmetric matrix A of size nxn and an integer p < n.
# Output: A real, orthonormal matrix X of size nxp such that trace(X'*A*X)
#         is maximized. That is, the columns of X form an orthonormal basis
#         of a dominant subspace of dimension p of A. These are thus
#         eigenvectors associated with the largest eigenvalues of A (in no
#         particular order). Sign is important: 2 is deemed a larger
#         eigenvalue than -5.
    
    # The optimization is performed on the Grassmann manifold, since only the
# space spanned by the columns of X matters. The implementation is short to
# show how Manopt can be used to quickly obtain a prototype. To make the
# implementation more efficient, one might first try to use the caching
# system, that is, use the optional 'store' arguments in the cost, grad and
# hess functions. Furthermore, using egrad2rgrad and ehess2rhess is quick
# and easy, but not always efficient. Having a look at the formulas
# implemented in these functions can help rewrite the code without them,
# possibly more efficiently.
    
    # See also: dominant_invariant_subspace_complex
    
    # This file is part of Manopt and is copyrighted. See the license file.
    
    # Main author: Nicolas Boumal, July 5, 2013
# Contributors:
    
    # Change log:
    
    #   NB Dec. 6, 2013:
#       We specify a max and initial trust region radius in the options.
    
    # Generate some random data to test the function
    if logical_not(exist('A','var')) or isempty(A):
        A=randn(128)
# dominant_invariant_subspace.m:38
        A=(A + A.T) / 2
# dominant_invariant_subspace.m:39
    
    if logical_not(exist('p','var')) or isempty(p):
        p=3
# dominant_invariant_subspace.m:42
    
    
    # Make sure the input matrix is square and symmetric
    n=size(A,1)
# dominant_invariant_subspace.m:46
    assert_(isreal(A),'A must be real.')
    assert_(size(A,2) == n,'A must be square.')
    assert_(norm(A - A.T,'fro') < dot(n,eps),'A must be symmetric.')
    assert_(p <= n,'p must be smaller than n.')
    
    Gr=grassmannfactory(n,p)
# dominant_invariant_subspace.m:53
    problem.M = copy(Gr)
# dominant_invariant_subspace.m:54
    problem.cost = copy(lambda X=None: - trace(dot(dot(X.T,A),X)))
# dominant_invariant_subspace.m:55
    problem.grad = copy(lambda X=None: dot(- 2,Gr.egrad2rgrad(X,dot(A,X))))
# dominant_invariant_subspace.m:56
    problem.hess = copy(lambda X=None,H=None: dot(- 2,Gr.ehess2rhess(X,dot(A,X),dot(A,H),H)))
# dominant_invariant_subspace.m:57
    
    # These can be commented out.
    # checkgradient(problem);
    # pause;
    # checkhessian(problem);
    # pause;
    
    # Issue a call to a solver. A random initial guess will be chosen and
    # default options are selected except for the ones we specify here.
    options.Delta_bar = copy(dot(8,sqrt(p)))
# dominant_invariant_subspace.m:68
    X,costX,info,options=trustregions(problem,[],options,nargout=4)
# dominant_invariant_subspace.m:69
    
    
    fprintf('Options used:\\n')
    disp(options)
    
    # Riemannian Hessian on the tangent space at (any) X. Computing the
    # spectrum at the solution gives us some idea of the conditioning of
    # the problem. If we were to implement a preconditioner for the
    # Hessian, this would also inform us on its performance.
    
    # Notice that (typically) all eigenvalues of the Hessian at the
    # solution are positive, i.e., we find an isolated minimizer. If we
    # replace the Grassmann manifold by the Stiefel manifold, hence still
    # optimizing over orthonormal matrices but ignoring the invariance
    # cost(XQ) = cost(X) for all Q orthogonal, then we see
    # dim O(p) = p(p-1)/2 zero eigenvalues in the Hessian spectrum, making
    # the optimizer not isolated anymore.
    if Gr.dim() < 512:
        evs=hessianspectrum(problem,X)
# dominant_invariant_subspace.m:88
        stairs(sort(evs))
        title(cat('Eigenvalues of the Hessian of the cost function ','at the solution'))
        xlabel('Eigenvalue number (sorted)')
        ylabel('Value of the eigenvalue')
    
    return X,info
    
if __name__ == '__main__':
    pass
    