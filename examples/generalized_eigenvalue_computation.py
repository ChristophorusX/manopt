# Autogenerated with SMOP 
from smop.core import *
# generalized_eigenvalue_computation.m

    
@function
def generalized_eigenvalue_computation(A=None,B=None,p=None,*args,**kwargs):
    varargin = generalized_eigenvalue_computation.varargin
    nargin = generalized_eigenvalue_computation.nargin

    # Returns orthonormal basis of the dominant invariant p-subspace of B^-1 A.
    
    # function [Xsol, Ssol] = generalized_eigenvalue_computation(A, B, p)
    
    # Input: A is a real, symmetric matrix of size nxn,
#        B is a symmetric positive definite matrix, same size as A
#        p is an integer such that p <= n.
    
    # Output: Xsol: a real, B-orthonormal matrix X of size nxp such that
#         trace(X'*A*X) is maximized, subject to X'*B*X = identity. 
#         That is, the columns of X form a B-orthonormal basis of a
#         dominant subspace of dimension p of B^(-1)*A. These are thus
#         generalized eigenvectors associated with the largest generalized
#         eigenvalues of B^(-1)*A  (in no particular order). Sign is
#         important: 2 is deemed a larger eigenvalue than -5.
#         Ssol: the eigenvalues associated with the eigenvectors Xsol, in a
#         vector.
# 
# We intend to solve the homogeneous system A*X = B*X*S,
# where S is a diagonal matrix of dominant eigenvalues of B^-1 A.
    
    
    # The optimization is performed on the generalized Grassmann manifold, 
# since only the space spanned by the columns of X matters in the
# optimization problem.
    
    # The optimization problem that we are solving here is 
# maximize trace(X'*A*X) subject to X'*B*X = eye(p). 
# Consequently, the solutions remain invariant to transformation
# X --> XQ, where Q is a p-by-p orthogonal matrix. The search space, in
# essence, is set of equivalence classes
# [X] = {XQ : X'*B*X = I and Q is orthogonal matrix}. This space is called
# the generalized Grassmann manifold.
# Before returning, Q is chosen such that Xsol = Xq matches the output one
# would expect from eigs.
    
    # See also dominant_invariant_subspace nonlinear_eigenspace
    
    # This file is part of Manopt and is copyrighted. See the license file.
    
    # Main author: Bamdev Mishra, June 30, 2015.
# Contributors:
# Change log:
    
    #     Aug. 10, 2016 (NB): the eigenvectors Xsol are now rotated by Vsol
#     before they are returned, to ensure the output matches what you would
#     normally expect calling eigs.
    
    # Generate some random data to test the function
    if logical_not(exist('A','var')) or isempty(A):
        n=128
# generalized_eigenvalue_computation.m:53
        A=randn(n)
# generalized_eigenvalue_computation.m:54
        A=(A + A.T) / 2
# generalized_eigenvalue_computation.m:55
    
    if logical_not(exist('B','var')) or isempty(B):
        n=size(A,1)
# generalized_eigenvalue_computation.m:58
        e=ones(n,1)
# generalized_eigenvalue_computation.m:59
        B=spdiags(cat(- e,dot(2,e),- e),arange(- 1,1),n,n)
# generalized_eigenvalue_computation.m:60
    
    
    if logical_not(exist('p','var')) or isempty(p):
        p=3
# generalized_eigenvalue_computation.m:64
    
    
    # Make sure the input matrix is square and symmetric
    n=size(A,1)
# generalized_eigenvalue_computation.m:68
    assert_(isreal(A),'A must be real.')
    assert_(size(A,2) == n,'A must be square.')
    assert_(norm(A - A.T,'fro') < dot(n,eps),'A must be symmetric.')
    assert_(p <= n,'p must be smaller than n.')
    
    # Grassmann manifold, i.e., the column space of all X such that
    # X'*B*X is identity.
    gGr=grassmanngeneralizedfactory(n,p,B)
# generalized_eigenvalue_computation.m:77
    problem.M = copy(gGr)
# generalized_eigenvalue_computation.m:79
    problem.cost = copy(lambda X=None: - trace(dot(dot(X.T,A),X)))
# generalized_eigenvalue_computation.m:80
    problem.egrad = copy(lambda X=None: dot(- 2,(dot(A,X))))
# generalized_eigenvalue_computation.m:81
    
    problem.ehess = copy(lambda X=None,H=None: dot(- 2,(dot(A,H))))
# generalized_eigenvalue_computation.m:82
    
    
    # Execute some checks on the derivatives for early debugging.
    # These things can be commented out of course.
    # checkgradient(problem);
    # pause;
    # checkhessian(problem);
    # pause;
    
    # Issue a call to a solver. A random initial guess will be chosen and
    # default options are selected except for the ones we specify here.
    options.Delta_bar = copy(dot(8,sqrt(p)))
# generalized_eigenvalue_computation.m:93
    options.tolgradnorm = copy(1e-07)
# generalized_eigenvalue_computation.m:94
    options.verbosity = copy(2)
# generalized_eigenvalue_computation.m:95
    
    Xsol,costXsol,info=trustregions(problem,[],options,nargout=3)
# generalized_eigenvalue_computation.m:96
    
    
    # To extract the eigenvalues, solve the small p-by-p symmetric 
    # eigenvalue problem.
    Vsol,Dsol=eig(dot(Xsol.T,(dot(A,Xsol))),nargout=2)
# generalized_eigenvalue_computation.m:100
    Ssol=diag(Dsol)
# generalized_eigenvalue_computation.m:101
    
    # matrix Vsol.
    Xsol=dot(Xsol,Vsol)
# generalized_eigenvalue_computation.m:105
    
    # norm(A*Xsol - B*Xsol*diag(Ssol));
    
    return Xsol,Ssol
    
if __name__ == '__main__':
    pass
    