# Autogenerated with SMOP 
from smop.core import *
# checkdiff.m

    
@function
def checkdiff(problem=None,x=None,d=None,force_gradient=None,*args,**kwargs):
    varargin = checkdiff.varargin
    nargin = checkdiff.nargin

    # Checks the consistency of the cost function and directional derivatives.
    
    # function checkdiff(problem)
# function checkdiff(problem, x)
# function checkdiff(problem, x, d)
    
    # checkdiff performs a numerical test to check that the directional
# derivatives defined in the problem structure agree up to first order with
# the cost function at some point x, along some direction d. The test is
# based on a truncated Taylor series (see online Manopt documentation).
    
    # Both x and d are optional and will be sampled at random if omitted.
    
    # See also: checkgradient checkhessian
    
    # If force_gradient = true (hidden parameter), then the function will call
# getGradient and infer the directional derivative, rather than call
# getDirectionalDerivative directly. This is used by checkgradient.
    
    # This file is part of Manopt: www.manopt.org.
# Original author: Nicolas Boumal, Dec. 30, 2012.
# Contributors: 
# Change log:
    
    #   April 3, 2015 (NB):
#       Works with the new StoreDB class system.
    
    if logical_not(exist('force_gradient','var')):
        force_gradient=copy(false)
# checkdiff.m:30
    
    
    # Verify that the problem description is sufficient.
    if logical_not(canGetCost(problem)):
        error('It seems no cost was provided.')
    
    if logical_not(force_gradient) and logical_not(canGetDirectionalDerivative(problem)):
        error('It seems no directional derivatives were provided.')
    
    if force_gradient and logical_not(canGetGradient(problem)):
        # Would normally issue a warning, but this function should only be
        # called with force_gradient on by checkgradient, which will
        # already have issued a warning.
        pass
    
    
    x_isprovided=exist('x','var') and logical_not(isempty(x))
# checkdiff.m:46
    d_isprovided=exist('d','var') and logical_not(isempty(d))
# checkdiff.m:47
    if logical_not(x_isprovided) and d_isprovided:
        error('If d is provided, x must be too, since d is tangent at x.')
    
    
    # If x and / or d are not specified, pick them at random.
    if logical_not(x_isprovided):
        x=problem.M.rand()
# checkdiff.m:55
    
    if logical_not(d_isprovided):
        d=problem.M.randvec(x)
# checkdiff.m:58
    
    # Compute the value f0 at f and directional derivative at x along d.
    storedb=StoreDB()
# checkdiff.m:62
    xkey=storedb.getNewKey()
# checkdiff.m:63
    f0=getCost(problem,x,storedb,xkey)
# checkdiff.m:64
    if logical_not(force_gradient):
        df0=getDirectionalDerivative(problem,x,d,storedb,xkey)
# checkdiff.m:67
    else:
        grad=getGradient(problem,x,storedb,xkey)
# checkdiff.m:69
        df0=problem.M.inner(x,grad,d)
# checkdiff.m:70
    
    
    # Compute the value of f at points on the geodesic (or approximation
    # of it) originating from x, along direction d, for stepsizes in a
    # large range given by h.
    h=logspace(- 8,0,51)
# checkdiff.m:76
    value=zeros(size(h))
# checkdiff.m:77
    for i in arange(1,length(h)).reshape(-1):
        y=problem.M.exp(x,d,h[i])
# checkdiff.m:79
        ykey=storedb.getNewKey()
# checkdiff.m:80
        value[i]=getCost(problem,y,storedb,ykey)
# checkdiff.m:81
    
    
    # Compute the linear approximation of the cost function using f0 and
    # df0 at the same points.
    model=polyval(cat(df0,f0),h)
# checkdiff.m:86
    
    err=abs(model - value)
# checkdiff.m:89
    
    loglog(h,err)
    title(sprintf(cat('Directional derivative check.\\nThe slope of the ','continuous line should match that of the dashed\\n','(reference) line over at least a few orders of ','magnitude for h.')))
    xlabel('h')
    ylabel('Approximation error')
    line('xdata',cat(1e-08,1.0),'ydata',cat(1e-08,100000000.0),'color','k','LineStyle','--','YLimInclude','off','XLimInclude','off')
    
    # as the square of the stepsize, i.e., in loglog scale, the error
    # should have a slope of 2.
    window_len=10
# checkdiff.m:108
    range_,poly=identify_linear_piece(log10(h),log10(err),window_len,nargout=2)
# checkdiff.m:109
    hold('all')
    loglog(h[range_],10.0 ** polyval(poly,log10(h[range_])),'LineWidth',3)
    hold('off')
    fprintf('The slope should be 2. It appears to be: %g.\\n',poly[1])
    fprintf(cat('If it is far from 2, then directional derivatives ','might be erroneous.\\n'))
    return
    
if __name__ == '__main__':
    pass
    