# Autogenerated with SMOP 
from smop.core import *
# pso/pso.m

    
@function
def pso(problem=None,x=None,options=None,*args,**kwargs):
    varargin = pso.varargin
    nargin = pso.nargin

    # Particle swarm optimization (PSO) for derivative-free minimization.
    
    # function [x, cost, info, options] = pso(problem)
# function [x, cost, info, options] = pso(problem, x0)
# function [x, cost, info, options] = pso(problem, x0, options)
# function [x, cost, info, options] = pso(problem, [], options)
    
    # Apply the Particle Swarm Optimization minimization algorithm to
# the problem defined in the problem structure, starting with the
# population x0 if it is provided (otherwise, a random population on the
# manifold is generated). A population is a cell containing points on the
# manifold. The number of elements in the cell must match the parameter
# options.populationsize.
    
    # To specify options whilst not specifying an initial guess, give x0 as []
# (the empty matrix).
    
    # None of the options are mandatory. See in code for details.
    
    # Based on the original PSO description in
#   http://particleswarm.info/nn951942.ps.
    
    # See also: manopt/solvers/neldermead/neldermead
    
    # This file is part of Manopt: www.manopt.org.
# Original author: Pierre Borckmans, Dec. 30, 2012.
# Contributors: Bamdev Mishra, June 18, 2014.
# Change log:
    
    #   June 18, 2014 (BM) :
#       Modified for handling product manifolds. Still need overall cleanup
#       to avoid potential issues, in particular wrt logarithms.
    
    #   June 23, 2014 (NB) :
#       Added some logic for handling of the populationsize option.
    
    #   April 5, 2015 (NB):
#       Working with the new StoreDB class system. The code keeps track of
#       storedb keys for all points, even though it is not strictly
#       necessary. This extra bookkeeping should help maintaining the code.
    
    
    # Verify that the problem description is sufficient for the solver.
    if logical_not(canGetCost(problem)):
        warning('manopt:getCost','No cost provided. The algorithm will likely abort.')
    
    
    # Dimension of the manifold
    dim=problem.M.dim()
# pso/pso.m:51
    
    localdefaults.storedepth = copy(0)
# pso/pso.m:54
    
    localdefaults.maxcostevals = copy(max(5000,dot(2,dim)))
# pso/pso.m:55
    localdefaults.maxiter = copy(max(500,dot(4,dim)))
# pso/pso.m:56
    localdefaults.populationsize = copy(min(40,dot(10,dim)))
# pso/pso.m:58
    localdefaults.nostalgia = copy(1.4)
# pso/pso.m:59
    localdefaults.social = copy(1.4)
# pso/pso.m:60
    
    localdefaults=mergeOptions(getGlobalDefaults(),localdefaults)
# pso/pso.m:63
    if logical_not(exist('options','var')) or isempty(options):
        options=struct()
# pso/pso.m:65
    
    options=mergeOptions(localdefaults,options)
# pso/pso.m:67
    if logical_not(isfield(problem.M,'log')):
        error(cat('The manifold problem.M must provide a logarithmic map, ','M.log(x, y). An approximate logarithm will do too.'))
    
    
    # Start timing for initialization
    timetic=tic()
# pso/pso.m:76
    
    # generate one at random.
    if logical_not(exist('x','var')) or isempty(x):
        x=cell(options.populationsize,1)
# pso/pso.m:81
        for i in arange(1,options.populationsize).reshape(-1):
            x[i]=problem.M.rand()
# pso/pso.m:83
    else:
        if logical_not(iscell(x)):
            error('The initial guess x0 must be a cell (a population).')
        if length(x) != options.populationsize:
            options.populationsize = copy(length(x))
# pso/pso.m:90
            warning('manopt:pso:size',cat('The option populationsize was forced to the size',' of the given initial population x0.'))
    
    
    
    # Create a store database and a key for each point x{i}
    storedb=StoreDB(options.storedepth)
# pso/pso.m:99
    xkey=cell(size(x))
# pso/pso.m:100
    for i in arange(1,numel(x)).reshape(-1):
        xkey[i]=storedb.getNewKey()
# pso/pso.m:102
    
    
    # Initialize personal best positions to the initial population
    y=copy(x)
# pso/pso.m:106
    ykey=copy(xkey)
# pso/pso.m:107
    
    xprev=copy(x)
# pso/pso.m:110
    xprevkey=copy(xkey)
# pso/pso.m:111
    
    
    # Initialize velocities for each particle
    v=cell(size(x))
# pso/pso.m:114
    for i in arange(1,numel(x)).reshape(-1):
        # random velocity to improve initial exploration
        v[i]=problem.M.randvec(x[i])
# pso/pso.m:117
        # v{i} = problem.M.zerovec();
    
    
    # Compute cost for each particle xi,
    # initialize personal best costs,
    # and setup a function evaluations counter.
    costs=zeros(size(x))
# pso/pso.m:125
    for i in arange(1,numel(x)).reshape(-1):
        costs[i]=getCost(problem,x[i],storedb,xkey[i])
# pso/pso.m:127
    
    fy=copy(costs)
# pso/pso.m:129
    costevals=options.populationsize
# pso/pso.m:130
    
    fbest,imin=min(costs,nargout=2)
# pso/pso.m:133
    xbest=x[imin]
# pso/pso.m:134
    xbestkey=xkey[imin]
# pso/pso.m:135
    
    
    # Iteration counter (at any point, iter is the number of fully executed
    # iterations so far)
    iter=0
# pso/pso.m:139
    
    # savestats will be called twice for the initial iterate (number 0),
    # which is unfortunate, but not problematic.
    stats=savestats()
# pso/pso.m:144
    info[1]=stats
# pso/pso.m:145
    info[min(10000,options.maxiter + 1)].iter = copy([])
# pso/pso.m:146
    
    while true:

        stats=savestats()
# pso/pso.m:151
        info[iter + 1]=stats
# pso/pso.m:152
        iter=iter + 1
# pso/pso.m:153
        storedb.purge()
        if options.verbosity >= 2:
            fprintf('Cost evals: %7d\\tBest cost: %+.8e\\n',costevals,fbest)
        # Start timing this iteration
        timetic=tic()
# pso/pso.m:164
        # BM: Stop if any particle triggers a stopping criterion.
        for i in numel(x).reshape(-1):
            stop,reason=stoppingcriterion(problem,x[i],options,info,iter,nargout=2)
# pso/pso.m:169
            if stop:
                break
        if stop:
            if options.verbosity >= 1:
                fprintf(cat(reason,'\\n'))
            break
        # Compute the inertia factor
        # (linearly decreasing from .9 to .4, from iter=0 to maxiter)
        w=0.4 + dot(0.5,(1 - iter / options.maxiter))
# pso/pso.m:185
        for i in arange(1,numel(x)).reshape(-1):
            # Get the position and past best position of particle i
            xi=x[i]
# pso/pso.m:191
            yi=y[i]
# pso/pso.m:192
            xiprev=xprev[i]
# pso/pso.m:195
            vi=v[i]
# pso/pso.m:196
            # composed of 3 contributions
            inertia=problem.M.lincomb(xi,w,problem.M.transp(xiprev,xi,vi))
# pso/pso.m:200
            nostalgia=problem.M.lincomb(xi,dot(rand(1),options.nostalgia),problem.M.log(xi,yi))
# pso/pso.m:201
            social=problem.M.lincomb(xi,dot(rand(1),options.social),problem.M.log(xi,xbest))
# pso/pso.m:202
            v[i]=problem.M.lincomb(xi,1,inertia,1,problem.M.lincomb(xi,1,nostalgia,1,social))
# pso/pso.m:204
        # Backup the current swarm positions
        xprev=copy(x)
# pso/pso.m:209
        xprevkey=copy(xkey)
# pso/pso.m:210
        # Update positions, personal bests and global best
        for i in arange(1,numel(x)).reshape(-1):
            # compute new position of particle i
            x[i]=problem.M.retr(x[i],v[i])
# pso/pso.m:215
            xkey[i]=storedb.getNewKey()
# pso/pso.m:216
            fxi=getCost(problem,x[i],storedb,xkey[i])
# pso/pso.m:218
            costevals=costevals + 1
# pso/pso.m:219
            costs[i]=fxi
# pso/pso.m:222
            if fxi < fy[i]:
                # update self-best cost and position
                fy[i]=fxi
# pso/pso.m:226
                y[i]=x[i]
# pso/pso.m:227
                ykey[i]=xkey[i]
# pso/pso.m:228
                if fy[i] < fbest:
                    fbest=fy[i]
# pso/pso.m:231
                    xbest=y[i]
# pso/pso.m:232
                    xbestkey=ykey[i]
# pso/pso.m:233

    
    
    
    info=info[1:iter]
# pso/pso.m:240
    
    
@function
def savestats(*args,**kwargs):
    varargin = savestats.varargin
    nargin = savestats.nargin

    stats.iter = copy(iter)
# pso/pso.m:244
    stats.cost = copy(fbest)
# pso/pso.m:245
    stats.costevals = copy(costevals)
# pso/pso.m:246
    stats.x = copy(x)
# pso/pso.m:247
    stats.v = copy(v)
# pso/pso.m:248
    stats.xbest = copy(xbest)
# pso/pso.m:249
    if iter == 0:
        stats.time = copy(toc(timetic))
# pso/pso.m:251
    else:
        stats.time = copy(info[iter].time + toc(timetic))
# pso/pso.m:253
    
    
    # BM: Begin storing user defined stats for the entire population
    num_old_fields=size(fieldnames(stats),1)
# pso/pso.m:257
    trialstats=applyStatsfun(problem,x[1],storedb,xkey[1],options,stats)
# pso/pso.m:258
    
    new_fields=fieldnames(trialstats)
# pso/pso.m:259
    num_new_fields=size(fieldnames(trialstats),1)
# pso/pso.m:260
    num_additional_fields=num_new_fields - num_old_fields
# pso/pso.m:261
    
    for jj in arange(1,num_additional_fields).reshape(-1):
        tempfield=new_fields[num_old_fields + jj]
# pso/pso.m:263
        setattr(stats,char(tempfield),cell(options.populationsize,1))
# pso/pso.m:264
    
    for ii in arange(1,options.populationsize).reshape(-1):
        tempstats=applyStatsfun(problem,x[ii],storedb,xkey[ii],options,stats)
# pso/pso.m:267
        for jj in arange(1,num_additional_fields).reshape(-1):
            tempfield=new_fields[num_old_fields + jj]
# pso/pso.m:269
            tempfield_value=getattr(tempstats,(char(tempfield)))
# pso/pso.m:270
            getattr(stats,(char(tempfield)))[ii]=tempfield_value
# pso/pso.m:271
    
    # BM: End storing
    
    return stats
    
if __name__ == '__main__':
    pass
    
    
    
    return stats
    
if __name__ == '__main__':
    pass
    