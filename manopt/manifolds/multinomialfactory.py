# Autogenerated with SMOP 
from smop.core import *
# multinomial/multinomialfactory.m

    
@function
def multinomialfactory(n=None,m=None,*args,**kwargs):
    varargin = multinomialfactory.varargin
    nargin = multinomialfactory.nargin

    # Manifold of n-by-m column-stochastic matrices with positive entries.
    
    # function M = multinomialfactory(n, m)
    
    # The returned structure M is a Manopt manifold structure to optimize over
# the set of n-by-m matrices with (strictly) positive entries and such that
# the entries of each column sum to one.
    
    # The metric imposed on the manifold is the Fisher metric such that 
# the set of n-by-m column-stochastic matrices (aka the multinomial manifold)
# is a Riemannian submanifold of the space of n-by-m matrices. Also it
# should be noted that the retraction operation that we define 
# is first order and as such the checkhessian tool cannot verify 
# the slope correctly.
#             
# The file is based on developments in the research paper
# Y. Sun, J. Gao, X. Hong, B. Mishra, and B. Yin,
# "Heterogeneous tensor decomposition for clustering via manifold
# optimization", arXiv:1504.01777, 2015.
    
    # Link to the paper: http://arxiv.org/abs/1504.01777.
    
    # Please cite the Manopt paper as well as the research paper:
#     @Techreport{sun2014multinomial,
#       Title   = {Heterogeneous tensor decomposition for clustering via manifold optimization},
#       Author  = {Sun, Y. and Gao, J. and Hong, X. and Mishra, B. and Yin, B.},
#       Journal = {Arxiv preprint arXiv:1504.01777},
#       Year    = {2014}
#     }
    
    # This file is part of Manopt: www.manopt.org.
# Original author: Bamdev Mishra, April 06, 2015.
# Contributors:
# Change log:
    
    M.name = copy(lambda : sprintf('%dx%d column-stochastic matrices with positive entries',n,m))
# multinomial/multinomialfactory.m:37
    M.dim = copy(lambda : dot((n - 1),m))
# multinomial/multinomialfactory.m:39
    
    M.inner = copy(iproduct)
# multinomial/multinomialfactory.m:42
    
@function
def iproduct(X=None,eta=None,zeta=None,*args,**kwargs):
    varargin = iproduct.varargin
    nargin = iproduct.nargin

    ip=sum((multiply(ravel(eta),ravel(zeta))) / ravel(X))
# multinomial/multinomialfactory.m:44
    return ip
    
if __name__ == '__main__':
    pass
    
    
    M.norm = copy(lambda X=None,eta=None: sqrt(M.inner(X,eta,eta)))
# multinomial/multinomialfactory.m:47
    M.dist = copy(lambda X=None,Y=None: error('multinomialfactory.dist not implemented yet.'))
# multinomial/multinomialfactory.m:49
    M.typicaldist = copy(lambda : dot(m,pi) / 2)
# multinomial/multinomialfactory.m:51
    
    
    # Column vector of ones of length n.
    e=ones(n,1)
# multinomial/multinomialfactory.m:54
    M.egrad2rgrad = copy(egrad2rgrad)
# multinomial/multinomialfactory.m:56
    
@function
def egrad2rgrad(X=None,egrad=None,*args,**kwargs):
    varargin = egrad2rgrad.varargin
    nargin = egrad2rgrad.nargin

    lambda_=- sum(multiply(X,egrad),1)
# multinomial/multinomialfactory.m:58
    
    rgrad=multiply(X,egrad) + multiply((dot(e,lambda_)),X)
# multinomial/multinomialfactory.m:59
    
    return rgrad
    
if __name__ == '__main__':
    pass
    
    
    M.ehess2rhess = copy(ehess2rhess)
# multinomial/multinomialfactory.m:62
    
@function
def ehess2rhess(X=None,egrad=None,ehess=None,eta=None,*args,**kwargs):
    varargin = ehess2rhess.varargin
    nargin = ehess2rhess.nargin

    
    # Riemannian gradient computation.
        # lambda is a row vector of length m.
    lambda_=- sum(multiply(X,egrad),1)
# multinomial/multinomialfactory.m:67
    rgrad=multiply(X,egrad) + multiply((dot(e,lambda_)),X)
# multinomial/multinomialfactory.m:68
    
    # lambdadot is a row vector of length m.
    lambdadot=- sum(multiply(eta,egrad),1) - sum(multiply(X,ehess),1)
# multinomial/multinomialfactory.m:72
    rgraddot=multiply(eta,egrad) + multiply(X,ehess) + multiply((dot(e,lambdadot)),X) + multiply((dot(e,lambda_)),eta)
# multinomial/multinomialfactory.m:73
    
    # impose. The computation of the correction term follows the use of
        # Koszul formula.
    correction_term=dot(- 0.5,(multiply(eta,rgrad))) / X
# multinomial/multinomialfactory.m:78
    rhess=rgraddot + correction_term
# multinomial/multinomialfactory.m:79
    
    rhess=M.proj(X,rhess)
# multinomial/multinomialfactory.m:82
    return rhess
    
if __name__ == '__main__':
    pass
    
    
    # Projection of the vector eta in the ambeint space onto the tangent
    # space.
    M.proj = copy(projection)
# multinomial/multinomialfactory.m:87
    
@function
def projection(X=None,eta=None,*args,**kwargs):
    varargin = projection.varargin
    nargin = projection.nargin

    alpha=sum(eta,1)
# multinomial/multinomialfactory.m:89
    
    etaproj=eta - multiply((dot(e,alpha)),X)
# multinomial/multinomialfactory.m:90
    return etaproj
    
if __name__ == '__main__':
    pass
    
    
    M.tangent = copy(M.proj)
# multinomial/multinomialfactory.m:93
    M.tangent2ambient = copy(lambda X=None,eta=None: eta)
# multinomial/multinomialfactory.m:94
    M.retr = copy(retraction)
# multinomial/multinomialfactory.m:96
    
@function
def retraction(X=None,eta=None,t=None,*args,**kwargs):
    varargin = retraction.varargin
    nargin = retraction.nargin

    if nargin < 3:
        t=1.0
# multinomial/multinomialfactory.m:99
    
    # A first-order retraction.
    Y=multiply(X,exp(dot(t,(eta / X))))
# multinomial/multinomialfactory.m:102
    
    Y=Y / (dot(e,(sum(Y,1))))
# multinomial/multinomialfactory.m:103
    
    # For numerical reasons, so that we avoid entries going to zero:
    Y=max(Y,eps)
# multinomial/multinomialfactory.m:105
    return Y
    
if __name__ == '__main__':
    pass
    
    
    M.exp = copy(exponential)
# multinomial/multinomialfactory.m:108
    
@function
def exponential(X=None,eta=None,t=None,*args,**kwargs):
    varargin = exponential.varargin
    nargin = exponential.nargin

    if nargin < 3:
        t=1.0
# multinomial/multinomialfactory.m:111
    
    Y=retraction(X,eta,t)
# multinomial/multinomialfactory.m:113
    warning('manopt:multinomialfactory:exp',cat('Exponential for the Multinomial manifold','manifold not implemented yet. Used retraction instead.'))
    return Y
    
if __name__ == '__main__':
    pass
    
    
    M.hash = copy(lambda X=None: cat('z',hashmd5(ravel(X))))
# multinomial/multinomialfactory.m:119
    M.rand = copy(random)
# multinomial/multinomialfactory.m:121
    
@function
def random(*args,**kwargs):
    varargin = random.varargin
    nargin = random.nargin

    # A random point in the ambient space.
    X=rand(n,m)
# multinomial/multinomialfactory.m:124
    
    X=X / (dot(e,(sum(X,1))))
# multinomial/multinomialfactory.m:125
    return X
    
if __name__ == '__main__':
    pass
    
    
    M.randvec = copy(randomvec)
# multinomial/multinomialfactory.m:128
    
@function
def randomvec(X=None,*args,**kwargs):
    varargin = randomvec.varargin
    nargin = randomvec.nargin

    # A random vector in the tangent space
    eta=randn(n,m)
# multinomial/multinomialfactory.m:131
    eta=M.proj(X,eta)
# multinomial/multinomialfactory.m:132
    
    nrm=M.norm(X,eta)
# multinomial/multinomialfactory.m:133
    eta=eta / nrm
# multinomial/multinomialfactory.m:134
    return eta
    
if __name__ == '__main__':
    pass
    
    
    M.lincomb = copy(matrixlincomb)
# multinomial/multinomialfactory.m:137
    M.zerovec = copy(lambda X=None: zeros(n,m))
# multinomial/multinomialfactory.m:139
    M.transp = copy(lambda X1=None,X2=None,d=None: projection(X2,d))
# multinomial/multinomialfactory.m:141
    
    M.vec = copy(lambda X=None,U=None: ravel(U))
# multinomial/multinomialfactory.m:144
    M.mat = copy(lambda X=None,u=None: reshape(u,n,m))
# multinomial/multinomialfactory.m:145
    M.vecmatareisometries = copy(lambda : false)
# multinomial/multinomialfactory.m:146
    return eta
    
if __name__ == '__main__':
    pass
    