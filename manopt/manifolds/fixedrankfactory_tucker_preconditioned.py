# Autogenerated with SMOP 
from smop.core import *
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m

    
@function
def fixedrankfactory_tucker_preconditioned(tensor_size=None,tensor_rank=None,*args,**kwargs):
    varargin = fixedrankfactory_tucker_preconditioned.varargin
    nargin = fixedrankfactory_tucker_preconditioned.nargin

    # Manifold of fixed multilinear rank tensors in Tucker format.
    
    # function M = fixedrankfactory_tucker_preconditioned(tensor_size, tensor_rank)
    
    # n1 = tensor_size(1);
# n2 = tensor_size(2);
# n3 = tensor_size(3);
# r1 = tensor_rank(1);
# r2 = tensor_rank(2);
# r3 = tensor_rank(3);
    
    # A point X on the manifold is represented as a structure with four
# fields: U1, U2, U3 and G. The matrices U1 (n1-by-r1), U2 (n2-by-r2),
# and U3 (n3-by-r3) are orthogonal matrices. G (r1-by-r2-by-r3) is a 
# multidimensional array.
    
    # Tangent vectors are represented as a structure with four fields: 
# U1, U2, U3, and G.
    
    # We exploit the quotient nature of Tucker decompositions to impose a
# scaled inner product on the manifold. This suits least-squares problems.
# For details, refer to the technical report:
# "{R}iemannian preconditioning for tensor completion",
# H. Kasai and B. Mishra, Arxiv preprint arXiv:1506.02159, 2015.
    
    # Paper link: http://arxiv.org/abs/1506.02159.
    
    # Please cite the Manopt paper as well as the research paper:
#     @TechReport{kasai2015precon,
#       Title   = {{R}iemannian preconditioning for tensor completion},
#       Author  = {Kasai, H. and Mishra, B.},
#       Journal = {Arxiv preprint arXiv:1506.02159},
#       Year    = {2015}
#     }
    
    # Original authors: Hiroyuki Kasai and Bamdev Mishra, June 5, 2015.
# Contributors: 
# Change log:
    
    if length(tensor_rank) > 3:
        error('Bad usage of fixedrankfactory_tucker_preconditioned. Currently, only handles 3-order tensors.')
    
    
    # Tensor size
    n1=tensor_size[1]
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:46
    n2=tensor_size[2]
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:47
    n3=tensor_size[3]
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:48
    
    r1=tensor_rank[1]
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:51
    r2=tensor_rank[2]
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:52
    r3=tensor_rank[3]
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:53
    speyer1=speye(r1)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:56
    
    speyer2=speye(r2)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:57
    speyer3=speye(r3)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:58
    M.name = copy(lambda : sprintf('G x U1 x U2 x U3 quotient Tucker manifold of %d-by-%d-by-%d tensor of rank %d-by-%d-by-%d.',n1,n2,n3,r1,r2,r3))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:61
    M.dim = copy(lambda : dot(n1,r1) - r1 ** 2 + dot(n2,r2) - r2 ** 2 + dot(n3,r3) - r3 ** 2 + dot(dot(r1,r2),r3))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:63
    
    # pretty much everywhere else)
    
@function
def prepare(X=None,*args,**kwargs):
    varargin = prepare.varargin
    nargin = prepare.nargin

    if logical_not(all(isfield(X,cellarray(['G1G1t','G1','G2G2t','G2','G3G3t','G3'])) == 1)):
        X.G1 = copy(reshape(X.G,r1,dot(r2,r3)))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:72
        X.G1G1t = copy(dot(X.G1,X.G1.T))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:73
        X.G2 = copy(reshape(permute(X.G,cat(2,1,3)),r2,dot(r1,r3)))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:76
        X.G2G2t = copy(dot(X.G2,X.G2.T))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:77
        X.G3 = copy(reshape(permute(X.G,cat(3,1,2)),r3,dot(r1,r2)))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:80
        X.G3G3t = copy(dot(X.G3,X.G3.T))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:81
    
    
    
    return X
    
if __name__ == '__main__':
    pass
    
    
    # Choice of metric is motivated by symmetry and tuned to least-squares
    # cost function
    M.inner = copy(iproduct)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:89
    
@function
def iproduct(X=None,eta=None,zeta=None,*args,**kwargs):
    varargin = iproduct.varargin
    nargin = iproduct.nargin

    X=prepare(X)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:91
    ip=trace(dot(X.G1G1t,(dot(eta.U1.T,zeta.U1)))) + trace(dot(X.G2G2t,(dot(eta.U2.T,zeta.U2)))) + trace(dot(X.G3G3t,(dot(eta.U3.T,zeta.U3)))) + (dot(ravel(eta.G).T,ravel(zeta.G)))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:92
    return ip
    
if __name__ == '__main__':
    pass
    
    M.norm = copy(lambda X=None,eta=None: sqrt(M.inner(X,eta,eta)))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:97
    M.dist = copy(lambda x=None,y=None: error('fixedrankfactory_tucker_preconditioned.dist not implemented yet.'))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:99
    M.typicaldist = copy(lambda : dot(dot(10,n1),r1))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:101
    
    
    skew=lambda X=None: dot(0.5,(X - X.T))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:103
    symm=lambda X=None: dot(0.5,(X + X.T))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:104
    M.egrad2rgrad = copy(egrad2rgrad)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:106
    
@function
def egrad2rgrad(X=None,egrad=None,*args,**kwargs):
    varargin = egrad2rgrad.varargin
    nargin = egrad2rgrad.nargin

    X=prepare(X)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:108
    
    
    SSU1=X.G1G1t
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:110
    ASU1=dot(2,symm[dot(SSU1,(dot(X.U1.T,egrad.U1)))])
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:111
    SSU2=X.G2G2t
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:113
    ASU2=dot(2,symm[dot(SSU2,(dot(X.U2.T,egrad.U2)))])
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:114
    SSU3=X.G3G3t
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:116
    ASU3=dot(2,symm[dot(SSU3,(dot(X.U3.T,egrad.U3)))])
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:117
    BU1=lyap(SSU1,- ASU1)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:120
    BU2=lyap(SSU2,- ASU2)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:121
    BU3=lyap(SSU3,- ASU3)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:122
    
    # is now on the tangent space. From the Riemannian submersion 
        # theory, it also belongs to the horizontal space. Therefore,
        # no need to further project it on the horizontal space.
    
    rgrad.U1 = copy((egrad.U1 - dot(X.U1,BU1)) / X.G1G1t)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:129
    rgrad.U2 = copy((egrad.U2 - dot(X.U2,BU2)) / X.G2G2t)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:130
    rgrad.U3 = copy((egrad.U3 - dot(X.U3,BU3)) / X.G3G3t)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:131
    rgrad.G = copy(egrad.G)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:132
    return rgrad
    
if __name__ == '__main__':
    pass
    
    
    
    
    M.ehess2rhess = copy(ehess2rhess)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:139
    
@function
def ehess2rhess(X=None,egrad=None,ehess=None,eta=None,*args,**kwargs):
    varargin = ehess2rhess.varargin
    nargin = ehess2rhess.nargin

    X=prepare(X)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:141
    
    
    # Riemannian gradient
    SSU1=X.G1G1t
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:144
    ASU1=dot(2,symm[dot(SSU1,(dot(X.U1.T,egrad.U1)))])
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:145
    SSU2=X.G2G2t
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:146
    ASU2=dot(2,symm[dot(SSU2,(dot(X.U2.T,egrad.U2)))])
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:147
    SSU3=X.G3G3t
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:148
    ASU3=dot(2,symm[dot(SSU3,(dot(X.U3.T,egrad.U3)))])
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:149
    BU1=lyap(SSU1,- ASU1)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:151
    BU2=lyap(SSU2,- ASU2)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:152
    BU3=lyap(SSU3,- ASU3)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:153
    rgrad.U1 = copy((egrad.U1 - dot(X.U1,BU1)) / X.G1G1t)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:155
    rgrad.U2 = copy((egrad.U2 - dot(X.U2,BU2)) / X.G2G2t)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:156
    rgrad.U3 = copy((egrad.U3 - dot(X.U3,BU3)) / X.G3G3t)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:157
    rgrad.G = copy(egrad.G)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:158
    
    
    eta_G1=reshape(eta.G,r1,dot(r2,r3))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:162
    
    eta_G2=reshape(permute(eta.G,cat(2,1,3)),r2,dot(r1,r3))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:163
    
    eta_G3=reshape(permute(eta.G,cat(3,1,2)),r3,dot(r1,r2))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:164
    
    egrad_G1=reshape(egrad.G,r1,dot(r2,r3))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:165
    
    egrad_G2=reshape(permute(egrad.G,cat(2,1,3)),r2,dot(r1,r3))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:166
    
    egrad_G3=reshape(permute(egrad.G,cat(3,1,2)),r3,dot(r1,r2))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:167
    
    ehess_G1=reshape(ehess.G,r1,dot(r2,r3))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:168
    
    ehess_G2=reshape(permute(ehess.G,cat(2,1,3)),r2,dot(r1,r3))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:169
    
    ehess_G3=reshape(permute(ehess.G,cat(3,1,2)),r3,dot(r1,r2))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:170
    
    rgrad_G1=reshape(rgrad.G,r1,dot(r2,r3))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:171
    
    rgrad_G2=reshape(permute(rgrad.G,cat(2,1,3)),r2,dot(r1,r3))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:172
    
    rgrad_G3=reshape(permute(rgrad.G,cat(3,1,2)),r3,dot(r1,r2))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:173
    
    
    ASU1dot=dot(2,symm[(dot(dot(2,symm[dot(X.G1,eta_G1.T)]),(dot(egrad_G1,X.G1.T)))) + dot(X.G1G1t,(dot(ehess_G1,X.G1.T) + dot(egrad_G1,eta_G1.T)))]) - dot(4,symm[dot(symm[dot(eta_G1,X.G1.T)],BU1)])
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:175
    ASU2dot=dot(2,symm[(dot(dot(2,symm[dot(X.G2,eta_G2.T)]),(dot(egrad_G2,X.G2.T)))) + dot(X.G2G2t,(dot(ehess_G2,X.G2.T) + dot(egrad_G2,eta_G2.T)))]) - dot(4,symm[dot(symm[dot(eta_G2,X.G2.T)],BU2)])
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:176
    ASU3dot=dot(2,symm[(dot(dot(2,symm[dot(X.G3,eta_G3.T)]),(dot(egrad_G3,X.G3.T)))) + dot(X.G3G3t,(dot(ehess_G3,X.G3.T) + dot(egrad_G3,eta_G3.T)))]) - dot(4,symm[dot(symm[dot(eta_G3,X.G3.T)],BU3)])
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:177
    SSU1dot=X.G1G1t
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:180
    SSU2dot=X.G2G2t
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:181
    SSU3dot=X.G3G3t
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:182
    BU1dot=lyap(SSU1dot,- ASU1dot)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:183
    BU2dot=lyap(SSU2dot,- ASU2dot)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:184
    BU3dot=lyap(SSU3dot,- ASU3dot)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:185
    Hess.U1 = copy((ehess.U1 - dot(eta.U1,BU1) - dot(X.U1,BU1dot) - dot(dot(2,rgrad.U1),symm[dot(eta_G1,X.G1.T)])) / X.G1G1t)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:188
    Hess.U2 = copy((ehess.U2 - dot(eta.U2,BU2) - dot(X.U2,BU2dot) - dot(dot(2,rgrad.U2),symm[dot(eta_G2,X.G2.T)])) / X.G2G2t)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:189
    Hess.U3 = copy((ehess.U3 - dot(eta.U3,BU3) - dot(X.U3,BU3dot) - dot(dot(2,rgrad.U3),symm[dot(eta_G3,X.G3.T)])) / X.G3G3t)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:190
    Hess.G = copy(ehess.G)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:191
    
    # The correction factor owes itself to the Koszul formula.
        # This is the Riemannian connection in the Euclidean space with the
        # scaled metric.
    
    
    Hess.U1 = copy(Hess.U1 + (dot(eta.U1,symm[dot(rgrad_G1,X.G1.T)]) + dot(rgrad.U1,symm[dot(eta_G1,X.G1.T)])) / X.G1G1t)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:201
    Hess.U2 = copy(Hess.U2 + (dot(eta.U2,symm[dot(rgrad_G2,X.G2.T)]) + dot(rgrad.U2,symm[dot(eta_G2,X.G2.T)])) / X.G2G2t)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:202
    Hess.U3 = copy(Hess.U3 + (dot(eta.U3,symm[dot(rgrad_G3,X.G3.T)]) + dot(rgrad.U3,symm[dot(eta_G3,X.G3.T)])) / X.G3G3t)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:203
    Hess.G = copy(Hess.G - permute(reshape(dot(symm[dot(rgrad.U1.T,eta.U1)],X.G1),r1,r2,r3),cat(1,2,3)) - permute(reshape(dot(symm[dot(rgrad.U2.T,eta.U2)],X.G2),r2,r1,r3),cat(2,1,3)) - permute(reshape(dot(symm[dot(rgrad.U3.T,eta.U3)],X.G3),r3,r1,r2),cat(2,3,1)))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:204
    
    # projection on the tangent space of the total space and then onto the horizontal
        # space. This is accomplished with the following operation.
    
    Hess=M.proj(X,Hess)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:212
    return Hess
    
if __name__ == '__main__':
    pass
    
    
    
    
    
    M.proj = copy(projection)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:220
    
@function
def projection(X=None,eta=None,*args,**kwargs):
    varargin = projection.varargin
    nargin = projection.nargin

    X=prepare(X)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:222
    
    
    # First, projection onto tangent space of total space
    SSU1=X.G1G1t
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:225
    ASU1=dot(2,symm[dot(dot(X.G1G1t,(dot(X.U1.T,eta.U1))),X.G1G1t)])
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:226
    BU1=lyap(SSU1,- ASU1)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:227
    eta.U1 = copy(eta.U1 - dot(X.U1,(BU1 / X.G1G1t)))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:228
    SSU2=X.G2G2t
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:230
    ASU2=dot(2,symm[dot(dot(X.G2G2t,(dot(X.U2.T,eta.U2))),X.G2G2t)])
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:231
    BU2=lyap(SSU2,- ASU2)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:232
    eta.U2 = copy(eta.U2 - dot(X.U2,(BU2 / X.G2G2t)))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:233
    SSU3=X.G3G3t
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:235
    ASU3=dot(2,symm[dot(dot(X.G3G3t,(dot(X.U3.T,eta.U3))),X.G3G3t)])
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:236
    BU3=lyap(SSU3,- ASU3)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:237
    eta.U3 = copy(eta.U3 - dot(X.U3,(BU3 / X.G3G3t)))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:238
    eta_G1=reshape(eta.G,r1,dot(r2,r3))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:241
    eta_G2=reshape(permute(eta.G,cat(2,1,3)),r2,dot(r1,r3))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:242
    eta_G3=reshape(permute(eta.G,cat(3,1,2)),r3,dot(r1,r2))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:243
    
    PU1=skew[dot((dot(X.U1.T,eta.U1)),X.G1G1t)] + skew[dot(X.G1,eta_G1.T)]
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:247
    PU2=skew[dot((dot(X.U2.T,eta.U2)),X.G2G2t)] + skew[dot(X.G2,eta_G2.T)]
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:248
    PU3=skew[dot((dot(X.U3.T,eta.U3)),X.G3G3t)] + skew[dot(X.G3,eta_G3.T)]
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:249
    
    # horizontal component. 
        # We use the Matlab's pcg function to solve the system efficiently.
        # We exploit the structure by designing a good preconditioner as well.
        # The preconditioner takes the block positive definite part of the
        # linear system.
    
    # Options for PCG
    tol_omegax_pcg=1e-06
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:259
    
    max_iterations_pcg=15
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:260
    
    
    # Preconditioner for PCG
    M1=kron(speyer1,SSU1) + kron(SSU1,speyer1)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:263
    M2=kron(speyer2,SSU2) + kron(SSU2,speyer2)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:264
    M3=kron(speyer3,SSU3) + kron(SSU3,speyer3)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:265
    Mprecon_pcg=sparse(zeros(r1 ** 2 + r2 ** 2 + r3 ** 2))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:267
    Mprecon_pcg[1:r1 ** 2,1:r1 ** 2]=M1
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:268
    Mprecon_pcg[1 + r1 ** 2:r1 ** 2 + r2 ** 2,1 + r1 ** 2:r1 ** 2 + r2 ** 2]=M2
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:269
    Mprecon_pcg[1 + r1 ** 2 + r2 ** 2:end(),1 + r1 ** 2 + r2 ** 2:end()]=M3
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:270
    
    Omegaxsol,unused=pcg(compute_residual,cat([ravel(PU1)],[ravel(PU2)],[ravel(PU3)]),tol_omegax_pcg,max_iterations_pcg,Mprecon_pcg,nargout=2)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:273
    Omega1=reshape(Omegaxsol[1:r1 ** 2],r1,r1)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:275
    Omega2=reshape(Omegaxsol[1 + r1 ** 2:r1 ** 2 + r2 ** 2],r2,r2)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:276
    Omega3=reshape(Omegaxsol[1 + r1 ** 2 + r2 ** 2:end()],r3,r3)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:277
    
@function
def compute_residual(Omegax=None,*args,**kwargs):
    varargin = compute_residual.varargin
    nargin = compute_residual.nargin

    Omegax1=reshape(Omegax[1:r1 ** 2],r1,r1)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:280
    Omegax2=reshape(Omegax[1 + r1 ** 2:r1 ** 2 + r2 ** 2],r2,r2)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:281
    Omegax3=reshape(Omegax[1 + r1 ** 2 + r2 ** 2:end()],r3,r3)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:282
    OffsetU1=dot(X.G1,(dot((kron(speyer3,Omegax2) + kron(Omegax3,speyer2)),X.G1.T)))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:284
    OffsetU2=dot(X.G2,(dot((kron(speyer3,Omegax1) + kron(Omegax3,speyer1)),X.G2.T)))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:285
    OffsetU3=dot(X.G3,(dot((kron(speyer2,Omegax1) + kron(Omegax2,speyer1)),X.G3.T)))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:286
    residual1=dot(Omegax1,SSU1) + dot(SSU1,Omegax1) - OffsetU1
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:288
    residual2=dot(Omegax2,SSU2) + dot(SSU2,Omegax2) - OffsetU2
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:289
    residual3=dot(Omegax3,SSU3) + dot(SSU3,Omegax3) - OffsetU3
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:290
    AOmegax=matlabarray(cat([ravel(residual1)],[ravel(residual2)],[ravel(residual3)]))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:292
    return AOmegax
    
if __name__ == '__main__':
    pass
    
    
    
    # Calculate projection along U1, U2, and U3
    etaproj.U1 = copy(eta.U1 - (dot(X.U1,Omega1)))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:297
    etaproj.U2 = copy(eta.U2 - (dot(X.U2,Omega2)))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:298
    etaproj.U3 = copy(eta.U3 - (dot(X.U3,Omega3)))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:299
    
    GOmega1=reshape(dot(Omega1,X.G1),r1,r2,r3)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:302
    GOmega2=permute(reshape(dot(Omega2,X.G2),r2,r1,r3),cat(2,1,3))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:303
    GOmega3=permute(reshape(dot(Omega3,X.G3),r3,r1,r2),cat(2,3,1))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:304
    etaproj.G = copy(eta.G - (- (GOmega1 + GOmega2 + GOmega3)))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:305
    return AOmegax
    
if __name__ == '__main__':
    pass
    
    
    
    
    M.tangent = copy(M.proj)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:311
    M.tangent2ambient = copy(lambda X=None,eta=None: eta)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:312
    M.retr = copy(retraction)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:314
    
@function
def retraction(X=None,eta=None,t=None,*args,**kwargs):
    varargin = retraction.varargin
    nargin = retraction.nargin

    if nargin < 3:
        t=1.0
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:317
    
    
    Y.G = copy((X.G + dot(t,eta.G)))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:320
    Y.U1 = copy(uf((X.U1 + dot(t,eta.U1))))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:321
    
    Y.U2 = copy(uf((X.U2 + dot(t,eta.U2))))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:322
    Y.U3 = copy(uf((X.U3 + dot(t,eta.U3))))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:323
    Y=prepare(Y)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:325
    return Y
    
if __name__ == '__main__':
    pass
    
    
    M.exp = copy(exponential)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:328
    
@function
def exponential(X=None,eta=None,t=None,*args,**kwargs):
    varargin = exponential.varargin
    nargin = exponential.nargin

    if nargin < 3:
        t=1.0
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:331
    
    Y=retraction(X,eta,t)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:333
    warning('manopt:fixedrankfactory_tucker_preconditioned:exp',cat('Exponential for fixed rank ','Tucker manifold not implemented yet. Used retraction instead.'))
    return Y
    
if __name__ == '__main__':
    pass
    
    
    M.hash = copy(lambda X=None: cat('z',hashmd5(cat([sum(ravel(X.U1))],[sum(ravel(X.U2))],[sum(ravel(X.U3))],[sum(ravel(X.G))]))))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:339
    
    # M.hash = @(X) ['z' hashmd5([X.U1(:); X.U2(:); X.U3(:); X.G(:)])];
    
    M.rand = copy(random)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:342
    
@function
def random(*args,**kwargs):
    varargin = random.varargin
    nargin = random.nargin

    #         # Random generator on the total space
        #         # Factors U1, U2, and U3 are on Stiefel manifolds, hence we reuse
        #         # their random generator.
        #         stiefell = stiefelfactory(n1, r1);
        #         stiefelm = stiefelfactory(n2, r2);
        #         stiefeln = stiefelfactory(n3, r3);
    
    #         X.U1 = stiefell.rand();
        #         X.U2 = stiefelm.rand();
        #         X.U3 = stiefeln.rand();
    
    #         # Random initialization: generalization of randn(r1, r1 = r2) in the
        #         # matrix case.
        #         X.G = randn(r1,r2,r3);
    
    
    #  Random generator on the fixed-rank space from a uniform distribution on [0, 1].
    U1,R1=qr(rand(n1,r1),0,nargout=2)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:361
    U2,R2=qr(rand(n2,r2),0,nargout=2)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:362
    U3,R3=qr(rand(n3,r3),0,nargout=2)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:363
    C=rand(r1,r2,r3)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:364
    C1=reshape(C,r1,dot(r2,r3))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:366
    CR1=reshape(dot(R1,C1),r1,r2,r3)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:367
    
    
    C2=reshape(permute(CR1,cat(2,1,3)),r2,dot(r1,r3))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:369
    CR1R2=permute(reshape(dot(R2,C2),r2,r1,r3),cat(2,1,3))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:370
    
    
    C3=reshape(permute(CR1R2,cat(3,1,2)),r3,dot(r1,r2))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:372
    CR1R2R3=permute(reshape(dot(R3,C3),r3,r1,r2),cat(2,3,1))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:373
    
    
    X.U1 = copy(U1)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:375
    X.U2 = copy(U2)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:376
    X.U3 = copy(U3)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:377
    X.G = copy(CR1R2R3)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:378
    
    X=prepare(X)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:382
    return X
    
if __name__ == '__main__':
    pass
    
    
    M.randvec = copy(randomvec)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:386
    
@function
def randomvec(X=None,*args,**kwargs):
    varargin = randomvec.varargin
    nargin = randomvec.nargin

    # A random vector on the horizontal space
    eta.U1 = copy(randn(n1,r1))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:389
    eta.U2 = copy(randn(n2,r2))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:390
    eta.U3 = copy(randn(n3,r3))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:391
    eta.G = copy(randn(r1,r2,r3))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:392
    eta=projection(X,eta)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:393
    nrm=M.norm(X,eta)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:394
    eta.U1 = copy(eta.U1 / nrm)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:395
    eta.U2 = copy(eta.U2 / nrm)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:396
    eta.U3 = copy(eta.U3 / nrm)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:397
    eta.G = copy(eta.G / nrm)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:398
    return eta
    
if __name__ == '__main__':
    pass
    
    
    M.lincomb = copy(lincomb)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:401
    M.zerovec = copy(lambda X=None: struct('U1',zeros(n1,r1),'U2',zeros(n2,r2),'U3',zeros(n3,r3),'G',zeros(r1,r2,r3)))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:403
    M.transp = copy(lambda x1=None,x2=None,d=None: projection(x2,d))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:406
    
    M.vec = copy(lambda X=None,U1=None: cat([ravel(U1.U1)],[ravel(U1.U2)],[ravel(U1.U3)],[ravel(U1.G)]))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:409
    M.mat = copy(lambda X=None,u=None: struct('U1',reshape(u[1:dot(n1,r1)],n1,r1),'U2',reshape(u[dot(n1,r1) + 1:dot(n1,r1) + dot(n2,r2)],n2,r2),'U3',reshape(u[dot(n1,r1) + dot(n2,r2) + 1:dot(n1,r1) + dot(n2,r2) + dot(n3,r3)],n3,r3),'G',reshape(u[dot(n1,r1) + dot(n2,r2) + dot(n3,r3) + 1:end()],r1,r2,r3)))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:410
    M.vecmatareisometries = copy(lambda : false)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:415
    return eta
    
if __name__ == '__main__':
    pass
    
    # Linear combination of tangent vectors
    
@function
def lincomb(X=None,a1=None,d1=None,a2=None,d2=None,*args,**kwargs):
    varargin = lincomb.varargin
    nargin = lincomb.nargin

    
    if nargin == 3:
        d.U1 = copy(dot(a1,d1.U1))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:423
        d.U2 = copy(dot(a1,d1.U2))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:424
        d.U3 = copy(dot(a1,d1.U3))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:425
        d.G = copy(dot(a1,d1.G))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:426
    else:
        if nargin == 5:
            d.U1 = copy(dot(a1,d1.U1) + dot(a2,d2.U1))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:428
            d.U2 = copy(dot(a1,d1.U2) + dot(a2,d2.U2))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:429
            d.U3 = copy(dot(a1,d1.U3) + dot(a2,d2.U3))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:430
            d.G = copy(dot(a1,d1.G) + dot(a2,d2.G))
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:431
        else:
            error('Bad use of fixedrankfactory_tucker_preconditioned.lincomb.')
    
    
    return d
    
if __name__ == '__main__':
    pass
    
    
@function
def uf(A=None,*args,**kwargs):
    varargin = uf.varargin
    nargin = uf.nargin

    L,unused,R=svd(A,0,nargout=3)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:439
    
    U=dot(L,R.T)
# fixedranktensors/fixedrankfactory_tucker_preconditioned.m:440
    return U
    
if __name__ == '__main__':
    pass
    